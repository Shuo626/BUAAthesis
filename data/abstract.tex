% !Mode:: "TeX:UTF-8"

% 中英文摘要
\begin{cabstract}
近年来，以神经网络为工具的深度学习在众多领域都取得了重大的成功，如计算机视觉，自然语言处理等。随着神经网络模型研究的深入和训练速度的加快，产生了大量的模型。同时，针对不同的功能，也产生了大量的异构的硬件设备，如传统的服务器，移动的手机，和一些专门的加速硬件等。所以，把众多的不同框架的神经网络模型部署到异构的硬件设备的需求越来越多。传统的部署方式，需要针对不同的深度学习框架和硬件设备的架构进行手动的调整，并不高效并且缺乏灵活性和扩展性。

TVM，Open Deep Learning Compiler Stack。TVM是一个深度学习的编译器，TVM旨在消除面向开发效率的深度学习框架和面向执行效率的硬件设备之间的差距。TVM目前支持主流的深度学习框架Pytorch，Tensorflow，Keras等，以及服务器，移动手机，树莓派等硬件设备，提供一个端到端的方式简化神经网络模型的部署流程。然而，TVM的使用仍较为复杂，需要用户进行多种软件的编译，安装，需要用户对深度学习框架和硬件的架构有一定的了解，所以本篇论文通过把TVM进行进一步的封装，提供统一简洁的接口，来实现多种深度学习框架模型到多种硬件设备的部署。
\end{cabstract}

\begin{eabstract}
In recent years, deep learning using neural networks as tools has achieved great success in many fields, such as computer vision and natural language processing. With the deepening of neural network model research and the acceleration of training speed, a large number of models have been produced. At the same time, for different functions, a large number of heterogeneous hardware devices have also been produced, such as traditional servers, mobile phones, and some specialized acceleration hardware. Therefore, there is an increasing demand for deploying neural network models of many different frameworks to heterogeneous hardware devices. Traditional deployment methods require manual adjustments to different deep learning frameworks and hardware device architectures, which are not efficient and lack flexibility and scalability.

TVM is a deep learning compiler. TVM aims to eliminate the gap between productivity-oriented deep learning frameworks and efficiency-oriented hardware devices. TVM currently supports mainstream deep learning frameworks such as Pytorch, Tensorflow, Keras, etc., as well as hardware devices such as servers, mobile phones, and Raspberry Pi, providing an end-to-end approach to simplify the deployment process of neural network models. However, the use of TVM is still relatively complicated, requiring users to compile and install a variety of software, and require users to have a certain understanding of the deep learning framework and hardware architecture. Therefore, this paper further encapsulates TVM to provide a unified and concise Interface to implement the deployment of multiple deep learning framework models to multiple hardware devices.
\end{eabstract}